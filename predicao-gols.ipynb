{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de instâncias: 380\n",
      "Número de atributos: 26\n",
      "match_id                    0\n",
      "stage                       0\n",
      "date                        0\n",
      "team_name_home              0\n",
      "team_name_away              0\n",
      "team_home_score             0\n",
      "team_away_score             0\n",
      "possession_home             0\n",
      "possession_away             0\n",
      "total_shots_home            0\n",
      "total_shots_away            0\n",
      "shots_on_target_home        0\n",
      "shots_on_target_away        0\n",
      "duels_won_home              0\n",
      "duels_won_away              0\n",
      "prediction_team_home_win    0\n",
      "prediction_draw             0\n",
      "prediction_team_away_win    0\n",
      "prediction_quantity         0\n",
      "location                    0\n",
      "lineup_home                 0\n",
      "lineup_away                 0\n",
      "player_names_home           0\n",
      "player_numbers_home         0\n",
      "player_names_away           0\n",
      "player_numbers_away         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregando o conjunto de dados\n",
    "data = pd.read_csv('./matches_brasileirao_serie_a_2022.csv')\n",
    "\n",
    "# verficando a quantidade de instâncias\n",
    "instances = data.shape[0]\n",
    "print('Número de instâncias: ' + str(instances))\n",
    "\n",
    "# verificando a quantidade de atributos\n",
    "attributes = data.shape[1]\n",
    "print('Número de atributos: ' + str(attributes))\n",
    "\n",
    "# Verificando a presença de dados ausentes\n",
    "print(data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possession_home</th>\n",
       "      <th>possession_away</th>\n",
       "      <th>total_shots_home</th>\n",
       "      <th>total_shots_away</th>\n",
       "      <th>shots_on_target_home</th>\n",
       "      <th>shots_on_target_away</th>\n",
       "      <th>duels_won_home</th>\n",
       "      <th>duels_won_away</th>\n",
       "      <th>both_scores_nonzero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     possession_home  possession_away  total_shots_home  total_shots_away  \\\n",
       "0               0.60             0.40                36                 4   \n",
       "1               0.41             0.59                13                 8   \n",
       "2               0.48             0.52                15                11   \n",
       "3               0.35             0.65                 6                13   \n",
       "4               0.57             0.43                17                 4   \n",
       "..               ...              ...               ...               ...   \n",
       "375             0.52             0.48                15                 6   \n",
       "376             0.52             0.48                17                 7   \n",
       "377             0.56             0.44                17                19   \n",
       "378             0.44             0.56                10                12   \n",
       "379             0.66             0.34                26                 3   \n",
       "\n",
       "     shots_on_target_home  shots_on_target_away  duels_won_home  \\\n",
       "0                       9                     3            0.48   \n",
       "1                       4                     4            0.54   \n",
       "2                       8                     2            0.58   \n",
       "3                       2                     7            0.62   \n",
       "4                       8                     2            0.51   \n",
       "..                    ...                   ...             ...   \n",
       "375                     5                     1            0.51   \n",
       "376                     9                     0            0.48   \n",
       "377                     4                     9            0.42   \n",
       "378                     3                     3            0.52   \n",
       "379                     6                     1            0.50   \n",
       "\n",
       "     duels_won_away  both_scores_nonzero  \n",
       "0              0.52                    1  \n",
       "1              0.46                    0  \n",
       "2              0.42                    0  \n",
       "3              0.38                    0  \n",
       "4              0.49                    1  \n",
       "..              ...                  ...  \n",
       "375            0.49                    0  \n",
       "376            0.52                    0  \n",
       "377            0.59                    1  \n",
       "378            0.48                    1  \n",
       "379            0.50                    0  \n",
       "\n",
       "[380 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando atributos desejáveis\n",
    "parsed_data = data.drop(\n",
    "  labels=['team_name_home', 'team_name_away', 'stage', 'match_id', 'date', 'location', \n",
    "          'lineup_home', 'lineup_away', 'player_names_home', 'player_numbers_home', \n",
    "          'player_names_away', 'player_numbers_away', 'prediction_team_home_win', \n",
    "          'prediction_draw', 'prediction_team_away_win', 'prediction_quantity'],\n",
    "  axis=1)\n",
    "\n",
    "# Criando atributo necessário para classificação\n",
    "parsed_data['both_scores_nonzero'] = np.where((parsed_data['team_home_score'] != 0) & \n",
    "                                              parsed_data['team_away_score']!=0, 1, 0)\n",
    "\n",
    "parsed_data = parsed_data.drop(\n",
    "  labels=['team_home_score', 'team_away_score'],\n",
    "  axis=1)\n",
    "\n",
    "parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12584/2474113760.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparsed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'return_nan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cat_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_encoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=parsed_data.columns, handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "data_encoded = encoder.fit_transform(parsed_data)\n",
    "data_encoded\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor()\n",
    "y_pred = lof.fit_predict(data_encoded)\n",
    "\n",
    "from numpy import where\n",
    "\n",
    "lofs_index = where(y_pred==-1)\n",
    "lofs_index # -> Não há Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo os dados em um conjunto de treinamento e testes (80% por 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divisão dos dados em conjunto de treinamento e teste\n",
    "train_data, test_data = train_test_split(parsed_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificando o tamanho dos conjuntos de treinamento e teste\n",
    "print(\"Tamanho do conjunto de treinamento:\", len(train_data))\n",
    "print(\"Tamanho do conjunto de teste:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o algotimo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definindo as variáveis de entrada (features) e o alvo (target)\n",
    "features = ['possession_home','possession_away','total_shots_home','total_shots_away',\n",
    "            'shots_on_target_home','shots_on_target_away','duels_won_home','duels_won_away']\n",
    "target = 'both_scores_nonzero'\n",
    "\n",
    "# Separando as features e o alvo do conjunto de treinamento e teste\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "####################################\n",
    "\n",
    "# Criando e treinando o modelo Decision Tree\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy_dt = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia do modelo Decision Tree:\", accuracy_dt)\n",
    "\n",
    "################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Criando e treinando o modelo Random Forest\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Acurácia do modelo Random Forest:\", accuracy_rf)\n",
    "\n",
    "################################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Criando e treinando o modelo Logistic Regression\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo Logistic Regression\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Acurácia do modelo Logistic Regression:\", accuracy_lr)\n",
    "\n",
    "######################################\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Criando e treinando o modelo SVM\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Acurácia do modelo SVM:\", accuracy_svm)\n",
    "\n",
    "##########################################\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Criando e treinando o modelo Naive Bayes\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo Naive Bayes\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Acurácia do modelo Naive Bayes:\", accuracy_nb)\n",
    "\n",
    "##############################\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Criando e treinando o modelo Gradient Boosting\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo Gradient Boosting\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Acurácia do modelo Gradient Boosting:\", accuracy_gb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando gráfico de acurácias\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "models = ['Decision Three', 'Random Forest', 'Logistic Regression', 'SVM', 'Naive Bayes', \n",
    "          'Gradient Boosting']\n",
    "accuracys = [accuracy_dt, accuracy_rf, accuracy_lr, accuracy_svm, accuracy_nb, accuracy_gb]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.bar(models, accuracys)\n",
    "\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Acurácias')\n",
    "plt.title('Gráfico de acurácias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Aplicando validação cruzada Decision Tree\n",
    "scores_dt = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"DecisionTree\")\n",
    "print(\"Acurácia média:\", scores_dt.mean())\n",
    "print(\"Desvio padrão:\", scores_dt.std())\n",
    "print(\"\\n\")\n",
    "#####################\n",
    "\n",
    "# Aplicando validação cruzada Random Forest\n",
    "scores_rf = cross_val_score(model_rf, X_train, y_train, cv=5)\n",
    "print(\"RandomForest\")\n",
    "print(\"Acurácia média:\", scores_rf.mean())\n",
    "print(\"Desvio padrão:\", scores_rf.std())\n",
    "print(\"\\n\")\n",
    "\n",
    "#####################\n",
    "\n",
    "# Aplicando validação cruzada Logistic Regression\n",
    "scores_lr = cross_val_score(model_lr, X_train, y_train, cv=5)\n",
    "print(\"LogisticRegression\")\n",
    "print(\"Acurácia média:\", scores_lr.mean())\n",
    "print(\"Desvio padrão:\", scores_lr.std())\n",
    "print(\"\\n\")\n",
    "\n",
    "#####################\n",
    "\n",
    "# Aplicando validação cruzada SVM\n",
    "scores_svm = cross_val_score(model_svm, X_train, y_train, cv=5)\n",
    "print(\"SVM\")\n",
    "print(\"Acurácia média:\", scores_svm.mean())\n",
    "print(\"Desvio padrão:\", scores_svm.std())\n",
    "print(\"\\n\")\n",
    "\n",
    "#####################\n",
    "\n",
    "# Aplicando validação cruzada Naive Bayes\n",
    "scores_nb = cross_val_score(model_nb, X_train, y_train, cv=5)\n",
    "print(\"NaiveBayes\")\n",
    "print(\"Acurácia média:\", scores_nb.mean())\n",
    "print(\"Desvio padrão:\", scores_nb.std())\n",
    "print(\"\\n\")\n",
    "\n",
    "#####################\n",
    "\n",
    "# Aplicando validação cruzada Naive Bayes\n",
    "scores_gb = cross_val_score(model_gb, X_train, y_train, cv=5)\n",
    "print(\"GradientBoosting\")\n",
    "print(\"Acurácia média:\", scores_gb.mean())\n",
    "print(\"Desvio padrão:\", scores_gb.std())\n",
    "print(\"\\n\")\n",
    "\n",
    "#####################\n",
    "\n",
    "# Gerando gráfico da validação cruzada\n",
    "models = ['Decision Three', 'Random Forest', 'Logistic Regression', 'SVM', \n",
    "          'Naive Bayes', ' Gradient Boosting']\n",
    "means = [scores_dt.mean(), scores_rf.mean(), scores_lr.mean(), scores_svm.mean(), \n",
    "         scores_nb.mean(), scores_gb.mean()]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "width_bar = 0.35  # Largura das barras\n",
    "\n",
    "# Posições das barras no eixo x\n",
    "mean_bar_position = np.arange(len(models))\n",
    "std_bar_position = mean_bar_position + width_bar\n",
    "\n",
    "plt.bar(models, means, width_bar)\n",
    "\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Média')\n",
    "plt.title('Gráfico de validação cruzada')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "stds = [scores_dt.std(), scores_rf.std(), scores_lr.std(), scores_svm.std(), scores_nb.std(), \n",
    "        scores_gb.std()]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.bar(models, stds, width_bar)\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Desvio padrão')\n",
    "plt.title('Gráfico de validação cruzada')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados de teste\n",
    "new_data = test_data \n",
    "\n",
    "# Realizando as previsões\n",
    "new_features = new_data[features]\n",
    "predictions = model.predict(new_features)\n",
    "\n",
    "new_data['prediction_result'] = predictions\n",
    "new_data['correct_prediction'] = (np.where((new_data['prediction_result'] == \n",
    "                                            new_data['both_scores_nonzero']), 1, 0))\n",
    "\n",
    "correct_prediction_count = new_data['correct_prediction'].cumsum()\n",
    "new_data['correct_prediction_count'] = correct_prediction_count\n",
    "\n",
    "final_correct_count = new_data['correct_prediction_count'].iloc[-1]\n",
    "\n",
    "print(\"Tamanho do conjunto de teste:\", len(new_data))\n",
    "print(\"Previsões Corretas:\", final_correct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilizando o modelo treinado para validar a base de jogos da serie B\n",
    "data2 = pd.read_csv('./matches_brasileirao_serie_b_2022.csv')\n",
    "parsed_data2 = data2.drop(\n",
    "  labels=['team_name_home', 'team_name_away', 'stage', 'match_id', 'date', 'location', \n",
    "          'lineup_home', 'lineup_away', 'player_names_home', 'player_numbers_home', \n",
    "          'player_names_away', 'player_numbers_away', 'prediction_team_home_win', \n",
    "          'prediction_draw', 'prediction_team_away_win', 'prediction_quantity'],\n",
    "  axis=1)\n",
    "\n",
    "parsed_data2['both_scores_nonzero'] = np.where((parsed_data2['team_home_score'] != 0) & \n",
    "                                              (parsed_data2['team_away_score']!=0), 1, 0)\n",
    "\n",
    "parsed_data2 = parsed_data2.drop(\n",
    "  labels=['team_home_score', 'team_away_score'],\n",
    "  axis=1)\n",
    "\n",
    "# Verficando a correlação dos atributos\n",
    "import seaborn as sns\n",
    "sns.heatmap(data=parsed_data2.corr(method='spearman'), annot=True, cmap='YlGnBu', \n",
    "            fmt='.2f', square=True)\n",
    "\n",
    "# Verificando a correlação dos atributos em relação a classe 'both_scores_nonzero'  \n",
    "correlations = parsed_data2.corr(method='spearman')['both_scores_nonzero']\n",
    "correlations_sorted = correlations.sort_values(ascending=False)\n",
    "#print('Correlação em relação a \"both_scores_nonzero\"')\n",
    "#print(correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "predictions2 = model.predict(parsed_data2[features])\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = accuracy_score(parsed_data2[target], predictions2)\n",
    "print(\"Acurácia do modelo Decision Tree:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo as previsões\n",
    "print(\"Previsões:\")\n",
    "\n",
    "parsed_data2['prediction_result'] = predictions2\n",
    "parsed_data2['correct_prediction'] = np.where((parsed_data2['prediction_result'] == parsed_data2['both_scores_nonzero']), 1, 0)\n",
    "\n",
    "\n",
    "correct_prediction_count = parsed_data2['correct_prediction'].cumsum()\n",
    "parsed_data2['correct_prediction_count'] = correct_prediction_count\n",
    "\n",
    "final_correct_count = parsed_data2['correct_prediction_count'].iloc[-1]\n",
    "\n",
    "print(\"Tamanho do conjunto de teste:\", len(parsed_data2))\n",
    "print(\"Previsões Corretas:\", final_correct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
